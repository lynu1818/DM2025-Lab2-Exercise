{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name: é™³ä¿å¦¤\n",
    "\n",
    "Student ID: 111062218\n",
    "\n",
    "GitHub ID: lynu1818\n",
    "\n",
    "Kaggle name: lynu1818\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![pic_ranking.png](./pics/image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/t/3a2df4c6d6b4417e8bf718ed648d7554)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "**Describe briefly each section, you can add graphs/charts to support your explanations.**\n",
    "\n",
    "### 1.1 Preprocessing Steps\n",
    "\n",
    "1. **Text Cleaning**:\n",
    "   - Converted all text to **lowercase** for consistency\n",
    "   - **Removed URLs** (they don't contain emotion information)\n",
    "   - **Kept emojis** - crucial for emotion detection (e.g., ðŸ˜Š, ðŸ˜¢, ðŸ˜¡)\n",
    "   - **Kept punctuation** - exclamation marks (!) and question marks (?) are strong emotional signals\n",
    "\n",
    "2. **Hashtag Integration**:\n",
    "   - Added hashtags from the JSON field directly to text (e.g., #happy, #sad)\n",
    "   - 5.2% of posts had hashtags that provide explicit emotional labels\n",
    "   - Example: \"I'm SO HAPPY!!!\" + [\"joy\"] â†’ \"i'm so happy!!! #joy\"\n",
    "\n",
    "3. **Space Normalization**:\n",
    "   - Removed excessive whitespace while preserving single spaces between words\n",
    "\n",
    "\n",
    "### 1.2 Feature Engineering Steps\n",
    "\n",
    "I used a Deep Learning approach with pre-trained transformer models, which minimizes manual feature engineering:\n",
    "\n",
    "1. **Tokenization with Pre-trained Tokenizers**:\n",
    "   - Used model-specific tokenizers (BERT, RoBERTa, BERTweet)\n",
    "   - **Max sequence length: 128 tokens** (covers 95%+ of texts in dataset)\n",
    "   - Dynamic padding for efficient batch processing\n",
    "\n",
    "2. **Implicit Features Learned by Transformers**:\n",
    "   - Contextual word embeddings (768-dimensional vectors)\n",
    "   - Attention mechanisms capture emotional patterns and word relationships\n",
    "   - Position-aware representations\n",
    "   - Sub-word tokenization handles rare words and social media slang\n",
    "\n",
    "### 1.3 Explanation of Your Model\n",
    "\n",
    "**Architecture Selection: Deep Learning vs Traditional ML**\n",
    "\n",
    "After consulting with ChatGPT and running preliminary experiments, I chose Deep Learning over traditional ML approaches (SVM, Random Forest) because:\n",
    "- Transformers excel at understanding contextual nuances in emotion\n",
    "- Pre-trained models have learned linguistic patterns from billions of words\n",
    "- My initial traditional ML experiments performed poorly (~30% F1), so I abandoned them early\n",
    "\n",
    "**Models Trained**:\n",
    "\n",
    "| Model | Public Score | \n",
    "|-------|--------------|\n",
    "| **roberta-base** | 0.6849|\n",
    "| **bert-base-uncased** | 0.6775|\n",
    "| **bertweet-base** | 0.6858|\n",
    "\n",
    "**Training Configuration**:\n",
    "- Split: 80% train, 20% validation\n",
    "- Max epochs: 50 with **early stopping** (saved best checkpoint based on validation F1)\n",
    "- Weight decay: 0.01 for regularization\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "\n",
    "### 2.1 Different Things I Tried\n",
    "\n",
    "**Ensemble Method - Soft Voting**\n",
    "- Combined all three models using **probability averaging**\n",
    "- Each model generates probability distribution over 6 emotions\n",
    "- Final prediction = argmax of averaged probabilities\n",
    "- **Public Score: 0.6964** (Best result!)\n",
    "\n",
    "**Ensemble Performance**:\n",
    "- Improved over best single model by ~1.2%\n",
    "- Agreement between models: 81-84%\n",
    "- Ensemble confidence: mean 0.74, highest on \"joy\" (0.83), lowest on \"disgust\" (0.44)\n",
    "\n",
    "### 2.2 Insights I Gained\n",
    "\n",
    "\n",
    "\n",
    "**Pre-trained Model Selection Matters**\n",
    "- BERTweet (Twitter-trained) performed well due to domain similarity\n",
    "- Model diversity in ensemble is more valuable than just using multiple checkpoints of the same model\n",
    "\n",
    "**Ensemble Benefits**\n",
    "- The ensemble outperforms each of the three individual models\n",
    "\n",
    "**Class Imbalance Impact**\n",
    "- Joy (50% of data) dominates predictions - models tend to predict it more\n",
    "- Disgust (2.5% of data) is hardest to classify\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the preprocessing steps in cells inside this section\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "\n",
    "\n",
    "# Load JSON data\n",
    "with open('data/final_posts.json', 'r') as f:\n",
    "    posts_data = json.load(f)\n",
    "\n",
    "# Extract post_id, text, and hashtags from nested JSON structure\n",
    "posts_list = []\n",
    "for item in posts_data:\n",
    "    post_info = item['root']['_source']['post']\n",
    "    posts_list.append({\n",
    "        'id': post_info['post_id'],\n",
    "        'text': post_info['text'],\n",
    "        'hashtags': post_info['hashtags']\n",
    "    })\n",
    "\n",
    "df_posts = pd.DataFrame(posts_list)\n",
    "print(f\"Posts loaded: {len(df_posts)}\")\n",
    "print(f\"Columns: {df_posts.columns.tolist()}\")\n",
    "df_posts.head()\n",
    "\n",
    "# Load emotion labels\n",
    "df_emotion = pd.read_csv('data/emotion.csv')\n",
    "print(f\"Emotion labels: {len(df_emotion)}\")\n",
    "print(f\"Columns: {df_emotion.columns.tolist()}\")\n",
    "df_emotion.head()\n",
    "\n",
    "# Load train/test split information\n",
    "df_split = pd.read_csv('data/data_identification.csv')\n",
    "print(f\"Split data: {len(df_split)}\")\n",
    "print(f\"Columns: {df_split.columns.tolist()}\")\n",
    "print(f\"\\nSplit distribution:\")\n",
    "print(df_split['split'].value_counts())\n",
    "df_split.head()\n",
    "\n",
    "# Merge all datasets\n",
    "df = df_posts.merge(df_split, on='id', how='left')\n",
    "df = df.merge(df_emotion, on='id', how='left')\n",
    "\n",
    "print(f\"Total merged data: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nDataset info:\")\n",
    "df.info()\n",
    "\n",
    "# Split into train and test\n",
    "df_train = df[df['split'] == 'train'].copy()\n",
    "df_test = df[df['split'] == 'test'].copy()\n",
    "\n",
    "print(f\"Training samples: {len(df_train)}\")\n",
    "print(f\"Test samples: {len(df_test)}\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"\\nTest set has labels: {df_test['emotion'].notna().sum()} (should be 0)\")\n",
    "print(f\"Train set has labels: {df_train['emotion'].notna().sum()}\")\n",
    "\n",
    "df.head(10)\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "def preprocess_text(text, hashtags=None):\n",
    "    \"\"\"\n",
    "    Preprocess text for emotion classification:\n",
    "    - Lowercase\n",
    "    - Remove URLs\n",
    "    - Keep emojis\n",
    "    - Keep punctuation (emotional cues)\n",
    "    - Remove excessive spaces\n",
    "    - Add hashtags from JSON field to text\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        text = \"\"\n",
    "    \n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    text = re.sub(r'www\\.(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    \n",
    "    # Add hashtags from the hashtags field (if available)\n",
    "    if hashtags is not None and isinstance(hashtags, list) and len(hashtags) > 0:\n",
    "        # Convert hashtags to lowercase and join them\n",
    "        hashtag_text = ' '.join([f\"#{tag.lower()}\" for tag in hashtags])\n",
    "        text = f\"{text} {hashtag_text}\"\n",
    "    \n",
    "    # Remove excessive spaces (multiple spaces to single space)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Strip leading/trailing spaces\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test the preprocessing function\n",
    "test_data = [\n",
    "    {\"text\": \"I'm SO HAPPY!!! ðŸ˜Š\", \"hashtags\": [\"joy\", \"happiness\"]},\n",
    "    {\"text\": \"Check this out: https://example.com/article\", \"hashtags\": []},\n",
    "    {\"text\": \"This is    terrible     ðŸ˜¢ðŸ˜¢ðŸ˜¢\", \"hashtags\": [\"sad\", \"crying\"]},\n",
    "    {\"text\": \"What a great day!!!\", \"hashtags\": [\"excited\", \"amazing\"]}\n",
    "]\n",
    "\n",
    "print(\"Preprocessing examples:\\n\")\n",
    "for data in test_data:\n",
    "    original = data['text']\n",
    "    hashtags = data['hashtags']\n",
    "    processed = preprocess_text(original, hashtags)\n",
    "    print(f\"Original:  {original}\")\n",
    "    print(f\"Hashtags:  {hashtags}\")\n",
    "    print(f\"Processed: {processed}\")\n",
    "    print()\n",
    "\n",
    "# Apply preprocessing to the entire dataset\n",
    "print(\"Preprocessing all texts...\")\n",
    "# Apply preprocessing with both text and hashtags\n",
    "df['text_clean'] = df.apply(lambda row: preprocess_text(row['text'], row['hashtags']), axis=1)\n",
    "df_train = df[df['split'] == 'train'].copy()\n",
    "df_test = df[df['split'] == 'test'].copy()\n",
    "\n",
    "print(f\"âœ“ Preprocessed {len(df)} texts\")\n",
    "print(f\"  - Training: {len(df_train)}\")\n",
    "print(f\"  - Test: {len(df_test)}\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Sample preprocessed texts:\\n\")\n",
    "for idx in df_train.sample(5).index:\n",
    "    print(f\"Original:  {df.loc[idx, 'text']}\")\n",
    "    print(f\"Hashtags:  {df.loc[idx, 'hashtags']}\")\n",
    "    print(f\"Processed: {df.loc[idx, 'text_clean']}\")\n",
    "    print(f\"Emotion:   {df.loc[idx, 'emotion']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the feature engineering steps in cells inside this section\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import torch\n",
    "from typing import Dict\n",
    "import os\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    \n",
    "# Prepare label mapping\n",
    "emotions = sorted(df_train['emotion'].unique())\n",
    "label2id = {label: idx for idx, label in enumerate(emotions)}\n",
    "id2label = {idx: label for label, idx in label2id.items()}\n",
    "\n",
    "print(\"Label mapping:\")\n",
    "for emotion, idx in label2id.items():\n",
    "    print(f\"  {emotion}: {idx}\")\n",
    "\n",
    "# Add numeric labels\n",
    "df_train['label'] = df_train['emotion'].map(label2id)\n",
    "df_test['label'] = -1  # Test set doesn't have labels\n",
    "\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df_train['label'].value_counts().sort_index())\n",
    "\n",
    "# Define model configurations\n",
    "MODEL_CONFIGS = {\n",
    "    'roberta-base': {\n",
    "        'model_name': 'roberta-base',\n",
    "        'max_length': 128,\n",
    "        'batch_size': 128,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 50\n",
    "    },\n",
    "    'bert-base-uncased': {\n",
    "        'model_name': 'bert-base-uncased',\n",
    "        'max_length': 128,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 50\n",
    "    },\n",
    "    'bertweet-base': {\n",
    "        'model_name': 'vinai/bertweet-base',\n",
    "        'max_length': 128,\n",
    "        'batch_size': 64,\n",
    "        'learning_rate': 2e-5,\n",
    "        'epochs': 50\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Model configurations:\")\n",
    "for model_key, config in MODEL_CONFIGS.items():\n",
    "    print(f\"\\n{model_key}:\")\n",
    "    for key, value in config.items():\n",
    "        print(f\"  {key}: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add the code related to the model implementation steps in cells inside this section\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Compute Mean F1 Score (macro)\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    f1_macro = f1_score(labels, predictions, average='macro')\n",
    "    return {'f1_macro': f1_macro}\n",
    "\n",
    "def tokenize_function(examples, tokenizer, max_length):\n",
    "    \"\"\"Tokenize texts\"\"\"\n",
    "    return tokenizer(\n",
    "        examples['text_clean'],\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        max_length=max_length\n",
    "    )\n",
    "\n",
    "def train_single_model(model_name, train_dataset, val_dataset, config, fold_num, output_dir):\n",
    "    \"\"\"Train a single model for one fold\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Training {model_name} - Fold {fold_num}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        config['model_name'],\n",
    "        num_labels=len(emotions),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id\n",
    "    )\n",
    "    \n",
    "    # Training arguments\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=config['learning_rate'],\n",
    "        per_device_train_batch_size=config['batch_size'],\n",
    "        per_device_eval_batch_size=config['batch_size'],\n",
    "        num_train_epochs=config['epochs'],\n",
    "        weight_decay=0.01,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1_macro',\n",
    "        logging_dir=f'{output_dir}/logs',\n",
    "        logging_steps=50,\n",
    "        save_total_limit=1,\n",
    "        seed=42,\n",
    "        fp16=torch.cuda.is_available(),  # Use mixed precision if GPU available\n",
    "    )\n",
    "    \n",
    "    # Trainer\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    \n",
    "    # Train\n",
    "    trainer.train()\n",
    "    \n",
    "    # Evaluate\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(f\"\\nFold {fold_num} Results:\")\n",
    "    print(f\"  Validation F1 (macro): {eval_results['eval_f1_macro']:.4f}\")\n",
    "    \n",
    "    return trainer, eval_results['eval_f1_macro']\n",
    "\n",
    "print(\"Helper functions defined successfully!\")\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Choose which models to train\n",
    "MODELS_TO_TRAIN_SIMPLE = [\n",
    "    'roberta-base',          \n",
    "    # 'bert-base-uncased',    \n",
    "    # 'bertweet-base',        \n",
    "]\n",
    "\n",
    "# Split training data into train/val (80/20)\n",
    "X_train_full = df_train['text_clean'].values\n",
    "y_train_full = df_train['label'].values\n",
    "\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SIMPLE TRAINING MODE (No K-Fold)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Training samples:   {len(X_train_split):,}\")\n",
    "print(f\"Validation samples: {len(X_val_split):,}\")\n",
    "print(f\"Total:              {len(X_train_full):,}\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Dictionary to store trained models\n",
    "all_trained_models_simple = {}\n",
    "all_scores_simple = {}\n",
    "\n",
    "# Train Models (Simple Version - One model per architecture)\n",
    "\n",
    "for model_key in MODELS_TO_TRAIN_SIMPLE:\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"# Training {model_key}\")\n",
    "    print(f\"{'#'*80}\\n\")\n",
    "    \n",
    "    config = MODEL_CONFIGS[model_key]\n",
    "    tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n",
    "    \n",
    "    # Prepare datasets\n",
    "    train_df = pd.DataFrame({\n",
    "        'text_clean': X_train_split,\n",
    "        'label': y_train_split\n",
    "    })\n",
    "    val_df = pd.DataFrame({\n",
    "        'text_clean': X_val_split,\n",
    "        'label': y_val_split\n",
    "    })\n",
    "    \n",
    "    # Convert to HuggingFace Dataset\n",
    "    print(\"Preparing datasets...\")\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    val_dataset = Dataset.from_pandas(val_df)\n",
    "    \n",
    "    # Tokenize\n",
    "    print(\"Tokenizing...\")\n",
    "    train_dataset = train_dataset.map(\n",
    "        lambda x: tokenize_function(x, tokenizer, config['max_length']),\n",
    "        batched=True,\n",
    "        desc=\"Tokenizing train\"\n",
    "    )\n",
    "    val_dataset = val_dataset.map(\n",
    "        lambda x: tokenize_function(x, tokenizer, config['max_length']),\n",
    "        batched=True,\n",
    "        desc=\"Tokenizing val\"\n",
    "    )\n",
    "    \n",
    "    # Set format for PyTorch\n",
    "    train_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    val_dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'label'])\n",
    "    \n",
    "    # Train model\n",
    "    print(f\"\\nStarting training on GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU'}\\n\")\n",
    "    output_dir = f'./models/{model_key}/simple'\n",
    "    trainer, val_f1 = train_single_model(\n",
    "        model_key, train_dataset, val_dataset, config, fold_num=1, output_dir=output_dir\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    all_trained_models_simple[model_key] = [trainer]  # Store as list for compatibility\n",
    "    all_scores_simple[model_key] = [val_f1]\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"âœ“ {model_key} trained successfully!\")\n",
    "    print(f\"  Validation F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Clean up GPU memory\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(f\"\\nâœ“ GPU Memory cleared\")\n",
    "\n",
    "print(\"\\n\" + \"#\"*80)\n",
    "print(\"# ALL MODELS TRAINED!\")\n",
    "print(\"#\"*80)\n",
    "\n",
    "# Summary\n",
    "print(\"\\nTraining Summary:\")\n",
    "print(\"=\"*80)\n",
    "for model_key in MODELS_TO_TRAIN_SIMPLE:\n",
    "    f1 = all_scores_simple[model_key][0]\n",
    "    print(f\"  {model_key:20s} : Validation F1 = {f1:.4f}\")\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
